{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS700 Example Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohamparikh94/PPLM/blob/master/CIS700_Example_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFmN0zIBXAuQ",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5UCitCoVLZC",
        "colab_type": "code",
        "outputId": "2f52c256-a065-4a6c-ba0a-f13a5feb45e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/sohamparikh94/PPLM.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PPLM'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 293 (delta 38), reused 58 (delta 18), pack-reused 212\u001b[K\n",
            "Receiving objects: 100% (293/293), 3.11 MiB | 15.59 MiB/s, done.\n",
            "Resolving deltas: 100% (132/132), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMxM3cm1X2Pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('PPLM')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ9z0QkTWt1V",
        "colab_type": "code",
        "outputId": "a30d80b6-846b-48aa-95e5-def2a4beeeba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (3.2.5)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.3.1)\n",
            "Collecting wordfreq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/7f/029a2d22362e785a258cd8bd5725f453817decfb31ac5d6dff0c472303d3/wordfreq-2.2.2.tar.gz (32.8MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8MB 89kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 4)) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 4)) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 4)) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 4)) (1.11.15)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 36.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 4)) (1.17.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 4)) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from wordfreq->-r requirements.txt (line 6)) (0.5.6)\n",
            "Collecting langcodes>=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/9a/e05169c2c00b11b21fb0af039644fa07210470a125aa508a460786c2e63f/langcodes-1.4.1.tar.gz (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 4)) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 4)) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers->-r requirements.txt (line 4)) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers->-r requirements.txt (line 4)) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers->-r requirements.txt (line 4)) (0.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->-r requirements.txt (line 4)) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->-r requirements.txt (line 4)) (0.14.1)\n",
            "Collecting marisa-trie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers->-r requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers->-r requirements.txt (line 4)) (0.15.2)\n",
            "Building wheels for collected packages: wordfreq, sacremoses, langcodes, marisa-trie\n",
            "  Building wheel for wordfreq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordfreq: filename=wordfreq-2.2.2-cp36-none-any.whl size=32816665 sha256=ea8f3d1bf8069ea7da8e95ee4a5ad7fc55a7292fdd38432418d6d7c9d523130e\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/2e/fc/e447859743f61cdf41873a5bcc11300c05fbd27631aea984e1\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=d4698f1ae8720aea523f517bdaf5775eab62013af9caaacb3a52b47c2694a3e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "  Building wheel for langcodes (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langcodes: filename=langcodes-1.4.1-cp36-none-any.whl size=4100892 sha256=1493a85b0f779e56cbb894b09cc42428c5fd26fdc76302969520fa77c6ddea79\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/20/3d/dc2010b4f7c0b786a06947530a962972caead0c58898f25a02\n",
            "  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=862297 sha256=40f6da8cb3ac1a4669bfebc9c5a46fbfbe74dcb7e1c9b0753790a98bbbab749c\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "Successfully built wordfreq sacremoses langcodes marisa-trie\n",
            "\u001b[31mERROR: wordfreq 2.2.2 has requirement regex<=2018.02.21,>=2017.07.11, but you'll have regex 2019.12.20 which is incompatible.\u001b[0m\n",
            "Installing collected packages: colorama, sentencepiece, sacremoses, tokenizers, transformers, marisa-trie, langcodes, wordfreq\n",
            "Successfully installed colorama-0.4.3 langcodes-1.4.1 marisa-trie-0.7.5 sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1 wordfreq-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfNwx_F_YZXE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "f8195978-b643-436e-8760-5840d5a96a29"
      },
      "source": [
        "from run_pplm import run_pplm_example\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5Yl_u6BYnS5",
        "colab_type": "text"
      },
      "source": [
        "# Let's generate some text!\n",
        "The ```run_pplm_example``` function generates the number of samples specified for the given prompt.\n",
        "### bag_of_words\n",
        "The different options you can use for ```bag_of_words``` are [\"kitchen\", \"legal\", \"military\", \"monsters\", \"politics\", \"positive_words\", \"religion\", \"science\", \"space\", \"technology\", \"minimal1\", \"minimal2\", \"minimal3\"], where \"minimal1\" contains \"dog\" and \"lamb\", \"minimal2\" contains only \"lamb\" and \"minimal3\" contains \"dog\" and \"cat\". \n",
        "\n",
        "### bow_type\n",
        "\n",
        "The different options you can use for this are $0,1,2,3$ and $4$, where $0$ indicates no weighting, $1$ indicates weighting by inverse of word frequencies, $2$ indicates weighting by log of inverse of word frequencies, $3$ indicates the average of $1$ and $2$, and $4$ indicates the exponential of word frequencies (**do NOT try 4! You'll run into CUDA errors and you will have to restart the runtime to get anything else using the GPU to work**). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU-V_66vO148",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prompt = 'A potato flew around my room'\n",
        "generated_texts = run_pplm_example(\n",
        "    cond_text=prompt,\n",
        "    num_samples=10,\n",
        "    bag_of_words='kitchen',\n",
        "    bow_type=0,\n",
        "    length=50,\n",
        "    stepsize=0.03,\n",
        "    sample=True,\n",
        "    num_iterations=3,\n",
        "    window_length=5,\n",
        "    gamma=1.5,\n",
        "    gm_scale=0.95,\n",
        "    kl_scale=0.01,\n",
        "    verbosity='quiet',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQh9VcKSKiNB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "46f4878a-8608-4664-8c25-ccdb4b97735a"
      },
      "source": [
        "generated_texts"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['prompt.ly/t/3b0e3c/\\n\\n# # # # # #\\n\\n# # # # # # #\\n\\n# # # # # # # #\\n\\n# # # # # can be used to',\n",
              " 'prompts:\\n\\n- use a default value for the prompt value\\n\\n- use the value of the command to print to console\\n\\n- use the value of the prompt to set a breakpoint in the program\\n\\n- use the command to',\n",
              " \"prompt to start playing, and then the game is over.\\n\\nIf the game is over, the user may continue playing.\\n\\nIf you're unable to stop the user from playing due to inability (or even inability to prevent the user from playing\",\n",
              " \"prompt:\\n\\nThe only thing you need to do to get this working is open your app and click on the 'More' button\\n\\nThe only thing you need to do to get this working is open your app and click on the 'More'\",\n",
              " 'prompts, and the \"previous state\" is the state the user can see when they enter the menu. The default is to show the list of current states, and can be changed using the can can can can can() function. can can can',\n",
              " 'prompts for an easy dinner with some friends?\\n\\na meal at a local restaurant?\\n\\na quick meal?\\n\\nor a meal you can share with someone else?\\n\\nor maybe even one you make for yourself at home?\\n\\n',\n",
              " 'prompts, it was a good time.\\n\\nIt was a very short one, but it did take me about 20 seconds to understand what it was.\\n\\nIt took me a few seconds to understand that my brain can make sense of it.',\n",
              " 'prompt for a conversation on the topic.\\n\\n\"I know, but I have my own idea.\"\\n\\n\"I don\\'t care about that. I just want to know what we are going to do. I want to know what we are going',\n",
              " 'prompt_name : \" prompt.prompt \"\\n\\n}\\n\\npub fn read_prompt <F : for_each ( & mut self ) > ( & mut self ) -> bool where F : for_each < string > = None',\n",
              " 'prompts\\n\\nprompt\\n\\nprompt\\n\\nprompt: set the prompt for the user to enter the prompt.\\n\\nPrompt.set_prompt(\\n\\nPrompt::get_p(),\\n\\n$prompt =']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd2Wj_tUKjmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}